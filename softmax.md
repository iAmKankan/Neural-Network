## Index
![dark](https://user-images.githubusercontent.com/12748752/141935752-90492d2e-7904-4f9f-a5a1-c4e59ddc3a33.png)
![light](https://user-images.githubusercontent.com/12748752/141935760-406edb8f-cb9b-4e30-9b69-9153b52c28b4.png)

## Introduction
![dark](https://user-images.githubusercontent.com/12748752/141935752-90492d2e-7904-4f9f-a5a1-c4e59ddc3a33.png)
> ### Softmax regression (or multinomial logistic regression) is a generalization of logistic regression to the case where we want to handle multiple classes.
* In logistic regression we assumed that the labels were binary: <img src="https://latex.codecogs.com/svg.image?y^{(i)}\&space;\in&space;\&space;\{0,1\}" title="y^{(i)}\ \in \ \{0,1\}" />. 



https://latex.codecogs.com/gif.image?\dpi{200}\alpha&space;+&space;\frac{2\beta}{\gamma}

* <img src="https://latex.codecogs.com/svg.image?y^2" title="y^2" />

<img src="https://latex.codecogs.com/svg.image?y^{(i)}" title="y^{(i)}" />
<img src="https://latex.codecogs.com/gif.image?\dpi{110}&space;y^{(i)}" title="y^{(i)}" />
* We used such a classifier to distinguish between two kinds of hand-written digits. Softmax regression allows us to handle y(i)∈{1,…,K} where K is the number of classes.
















## References
![dark](https://user-images.githubusercontent.com/12748752/141935752-90492d2e-7904-4f9f-a5a1-c4e59ddc3a33.png)
* [Deeplearning Satanford Univercity](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)
